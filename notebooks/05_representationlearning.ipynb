{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b4da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils import count_params\n",
    "\n",
    "np.random.seed(13)\n",
    "torch.random.manual_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208976aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist1d.data import get_dataset_args, make_dataset\n",
    "\n",
    "# disable noise for a clear reference\n",
    "clean_config = get_dataset_args()\n",
    "clean_config.iid_noise_scale = 0\n",
    "clean_config.corr_noise_scale = 0\n",
    "clean_config.seed = 40\n",
    "clean = make_dataset(clean_config)\n",
    "cleanX, cleany = clean[\"x\"], clean[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409e32e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Now, let's plot the data which we would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(2, 5, figsize=(14, 5), sharex=True, sharey=True)\n",
    "\n",
    "for sample in range(10):\n",
    "    col = sample % 5\n",
    "    row = sample // 5\n",
    "    ax[row, col].plot(cleanX[sample, ...], label=\"clean\", color=\"green\")\n",
    "    label = cleany[sample]\n",
    "    ax[row, col].set_title(f\"label {label}\")\n",
    "    if row == 1:\n",
    "        ax[row, col].set_xlabel(f\"samples / a.u.\")\n",
    "    if col == 0:\n",
    "        ax[row, col].set_ylabel(f\"intensity / a.u.\")\n",
    "    if col == 4 and row == 0:\n",
    "        ax[row, col].legend()\n",
    "\n",
    "f.suptitle(\"MNIST1D examples\")\n",
    "f.savefig(\"mnist1d_cleanonly_first10.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MyEncoder(torch.nn.Module):\n",
    "    def __init__(self, nlayers: int = 3, nchannels=16):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "\n",
    "        for i in range(nlayers - 1):\n",
    "            inchannels = 1 if i == 0 else nchannels\n",
    "            # convolve and shrink input width by 2x\n",
    "            self.layers.append(\n",
    "                torch.nn.Conv1d(\n",
    "                    in_channels=inchannels,\n",
    "                    out_channels=nchannels,\n",
    "                    kernel_size=5,\n",
    "                    padding=2,\n",
    "                    stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # convolve and keep input width\n",
    "        self.layers.append(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=nchannels, out_channels=1, kernel_size=3, padding=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # flatten and add a linear tail\n",
    "        self.layers.append(torch.nn.Flatten())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutions in torch require an explicit channel dimension to be\n",
    "        # present in the data in other words:\n",
    "        # inputs of size (nbatch, 40) do not work,\n",
    "        # inputs of size (nbatch, 1, 40) do work\n",
    "        if len(x.shape) == 2:\n",
    "            x = torch.unsqueeze(x, dim=1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecoder(torch.nn.Module):\n",
    "    def __init__(self, nlayers: int = 3, nchannels=16):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "\n",
    "        for i in range(nlayers - 1):\n",
    "            inchannels = 1 if i == 0 else nchannels\n",
    "            # deconvolve/Upsample and grow input width by 2x\n",
    "            self.layers.append(\n",
    "                torch.nn.ConvTranspose1d(\n",
    "                    in_channels=inchannels,\n",
    "                    out_channels=nchannels,\n",
    "                    kernel_size=5,\n",
    "                    padding=2,\n",
    "                    stride=2,\n",
    "                    output_padding=1,\n",
    "                )\n",
    "            )\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # convolve and keep input width\n",
    "        self.layers.append(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=nchannels, out_channels=1, kernel_size=3, padding=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutions in torch require an explicit channel dimension to be\n",
    "        # present in the data in other words:\n",
    "        # inputs of size (nbatch, 40) do not work,\n",
    "        # inputs of size (nbatch, 1, 40) do work\n",
    "        if len(x.shape) == 2:\n",
    "            x = torch.unsqueeze(x, dim=1)\n",
    "\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d8011",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, nlayers: int = 3, nchannels=16):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = MyEncoder(nlayers, nchannels)\n",
    "        self.dec = MyDecoder(nlayers, nchannels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # construct the latents\n",
    "        h = self.enc(x)\n",
    "\n",
    "        # perform reconstruction\n",
    "        x_prime = self.dec(h)\n",
    "\n",
    "        return x_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174191d6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Training an autoencoder\n",
    "\n",
    "Training the autoencoder works in the same line as training for regression from the last episode.\n",
    "\n",
    "1. create the dataset\n",
    "2. create the loaders\n",
    "3. setup the model\n",
    "4. setup the optimizer\n",
    "5. loop through epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e152af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from utils import MNIST1D\n",
    "\n",
    "training_data = MNIST1D(mnist1d_args=clean_config)\n",
    "test_data = MNIST1D(mnist1d_args=clean_config, train=False)\n",
    "\n",
    "nsamples = len(training_data) + len(test_data)\n",
    "assert nsamples == 4000, f\"number of samples for MNIST1D is not 4000 but {nsamples}\"\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "autoemodel = MyAutoencoder()\n",
    "learning_rate = 1e-3\n",
    "max_epochs = 30\n",
    "log_every = 5\n",
    "\n",
    "optimizer = torch.optim.AdamW(autoemodel.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()  # our loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67721941",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# write the training loop\n",
    "def train_autoencoder(\n",
    "    model, opt, crit, train_dataloader, test_dataloader, max_epochs, log_every=5\n",
    "):\n",
    "    results = {\"train_losses\": [], \"test_losses\": []}\n",
    "    ntrainsteps = len(train_dataloader)\n",
    "    nteststeps = len(test_dataloader)\n",
    "    train_loss, test_loss = torch.zeros((ntrainsteps,)), torch.zeros((nteststeps,))\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # perform training for one epoch\n",
    "        for idx, (X, _) in enumerate(train_dataloader):\n",
    "            # forward pass\n",
    "            X_prime = model(X)\n",
    "\n",
    "            # compute loss\n",
    "            loss = crit(X_prime, X)\n",
    "\n",
    "            # compute gradient\n",
    "            loss.backward()\n",
    "\n",
    "            # apply weight update rule\n",
    "            opt.step()\n",
    "\n",
    "            # set gradients to 0\n",
    "            opt.zero_grad()\n",
    "\n",
    "            train_loss[idx] = loss.item()\n",
    "\n",
    "        for idx, (X_test, _) in enumerate(test_dataloader):\n",
    "            X_prime_test = model(X_test)\n",
    "            loss_ = crit(X_prime_test, X_test)\n",
    "            test_loss[idx] = loss_.item()\n",
    "\n",
    "        results[\"train_losses\"].append(train_loss.mean())\n",
    "        results[\"test_losses\"].append(test_loss.mean())\n",
    "\n",
    "        if epoch % log_every == 0 or (epoch + 1) == max_epochs:\n",
    "            print(\n",
    "                f\"{epoch+1:02.0f}/{max_epochs} :: training loss {train_loss.mean():03.4f}; test loss {test_loss.mean():03.4f}\"\n",
    "            )\n",
    "    return results\n",
    "\n",
    "\n",
    "print(f\"Initialized autoencoder with {count_params(autoemodel)} parameters\")\n",
    "results = train_autoencoder(\n",
    "    autoemodel,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    max_epochs,\n",
    "    log_every,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax[0].plot(results[\"train_losses\"], color=\"b\", label=\"train\")\n",
    "ax[0].plot(results[\"test_losses\"], color=\"orange\", label=\"test\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"avergage MSE Loss / a.u.\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "\n",
    "index = 0\n",
    "# perform prediction again\n",
    "last_x, last_y = test_data[index]\n",
    "last_x_prime = autoemodel(last_x.unsqueeze(0))\n",
    "\n",
    "# prepare tensors for plotting\n",
    "last_in = last_x.detach().squeeze().numpy()\n",
    "last_out = last_x_prime.detach().squeeze().numpy()\n",
    "\n",
    "ax[1].plot(last_in, color=\"b\", label=\"test input\")\n",
    "ax[1].plot(last_out, color=\"orange\", label=\"test prediction\")\n",
    "ax[1].set_xlabel(\"samples / a.u.\")\n",
    "ax[1].set_ylabel(\"intensity / a.u.\")\n",
    "ax[1].set_title(f\"Conv-based Autoencoder, label = {last_y.detach().item()}\")\n",
    "ax[1].legend()\n",
    "\n",
    "f.savefig(\"representationlearning-autoencoder-loss.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd4c8d",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Representation Learning\n",
    "\n",
    "Effective Machine Learning is often about finding a good and flexible model that can represent high-dimensional data well. The autoencoder can be such an architecture depending on its design and the input data. In practice, the community has started to use the latent representation for all kinds of applications. But you should be aware, that the created representations can be task specific.\n",
    "\n",
    "## Classifying MNIST1D\n",
    "\n",
    "Similar to [MNIST](https://yann.lecun.com/exdb/mnist/), `mnist1d` can be used for the task of classification. In other words, given an input sequence, we only want to predict the class label `[0,1,...,9]` that the image belongs to. Classification has been one of the driving forces behind progress in machine learning since [ImageNet 2012]() - for better or worse. In science, classification is used rarely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a54ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://github.com/greydanus/mnist1d/blob/dc46206f1e1ad7249c96e3042efca0955a6b5d35/notebooks/models.py#L36C1-L54C65\n",
    "class ConvBase(torch.nn.Module):\n",
    "    def __init__(self, output_size, channels=25, linear_in=10):\n",
    "        super(ConvBase, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(1, channels, 5, stride=2, padding=2)\n",
    "        self.conv2 = torch.nn.Conv1d(channels, channels, 3, stride=2, padding=1)\n",
    "        self.conv3 = torch.nn.Conv1d(channels, channels, 3, stride=1, padding=1)\n",
    "        self.linear = torch.nn.Linear(\n",
    "            linear_in * channels, output_size\n",
    "        )  # flattened channels -> 10 (assumes input has dim 50)\n",
    "\n",
    "    def forward(self, x, verbose=False):  # the print statements are for debugging\n",
    "        x = x.view(-1, 1, x.shape[-1])\n",
    "        h1 = self.conv1(x).relu()\n",
    "        h2 = self.conv2(h1).relu()\n",
    "        h3 = self.conv3(h2).relu()\n",
    "        h3 = h3.view(h3.shape[0], -1)  # flatten the conv features\n",
    "        return self.linear(h3)  # a linear classifier goes on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66046975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "\n",
    "\n",
    "def train_classifier(\n",
    "    model, opt, crit, train_dataloader, test_dataloader, max_epochs, log_every=5\n",
    "):\n",
    "    results = {\n",
    "        \"train_losses\": [],\n",
    "        \"test_losses\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"test_accuracy\": [],\n",
    "    }\n",
    "    ntrainsteps = len(train_dataloader)\n",
    "    nteststeps = len(test_dataloader)\n",
    "    train_loss, test_loss = torch.zeros((ntrainsteps,)), torch.zeros((nteststeps,))\n",
    "    train_acc, test_acc = np.zeros((ntrainsteps,)), np.zeros((nteststeps,))\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # perform training for one epoch\n",
    "        for idx, (X, y) in enumerate(train_dataloader):\n",
    "            # forward pass\n",
    "            y_hat = model(X)\n",
    "\n",
    "            # compute loss\n",
    "            loss = crit(y_hat, y)\n",
    "\n",
    "            # compute gradient\n",
    "            loss.backward()\n",
    "\n",
    "            # apply weight update rule\n",
    "            opt.step()\n",
    "\n",
    "            # set gradients to 0\n",
    "            opt.zero_grad()\n",
    "\n",
    "            train_loss[idx] = loss.item()\n",
    "            train_acc[idx] = accuracy(\n",
    "                y.detach().cpu().numpy(), y_hat.argmax(-1).cpu().numpy()\n",
    "            )\n",
    "\n",
    "        for idx, (X_test, y_test) in enumerate(test_dataloader):\n",
    "            y_hat_test = model(X_test)\n",
    "            loss_ = crit(y_hat_test, y_test)\n",
    "            test_loss[idx] = loss_.item()\n",
    "            test_acc = accuracy(\n",
    "                y_test.detach().cpu().numpy(), y_hat_test.argmax(-1).cpu().numpy()\n",
    "            )\n",
    "\n",
    "        results[\"train_losses\"].append(train_loss.mean())\n",
    "        results[\"test_losses\"].append(test_loss.mean())\n",
    "        results[\"train_accuracy\"].append(np.mean(train_acc))\n",
    "        results[\"test_accuracy\"].append(np.mean(test_acc))\n",
    "\n",
    "        if epoch % log_every == 0 or (epoch + 1) == max_epochs:\n",
    "            print(\n",
    "                f\"{epoch+1:02.0f}/{max_epochs} :: training loss {train_loss.mean():03.4f}; test loss {test_loss.mean():03.4f} \"\n",
    "                f\"training acc {np.mean(train_acc):01.4f}; test acc {np.mean(test_acc):01.4f}\"\n",
    "            )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we reuse the dataloaders from above\n",
    "classmodel = ConvBase(10, channels=32)\n",
    "print(f\"Initialized ConvBase model with {count_params(classmodel)} parameters\")\n",
    "classopt = torch.optim.AdamW(classmodel.parameters(), lr=1e-3)\n",
    "classcrit = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "classifier_results = train_classifier(\n",
    "    classmodel, classopt, classcrit, train_dataloader, test_dataloader, max_epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daad567",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax[0].plot(classifier_results[\"train_losses\"], color=\"b\", label=\"train\")\n",
    "ax[0].plot(classifier_results[\"test_losses\"], color=\"orange\", label=\"test\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"avergage MSE Loss / a.u.\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(classifier_results[\"train_accuracy\"], color=\"b\", label=\"train\")\n",
    "ax[1].plot(classifier_results[\"test_accuracy\"], color=\"orange\", label=\"test\")\n",
    "ax[1].set_xlabel(\"epoch\")\n",
    "ax[1].set_ylabel(\"avergage Accuracy / a.u.\")\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "ax[1].legend()\n",
    "\n",
    "f.savefig(\"representationlearning-classifier-loss.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0437c5c",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "We have trained two networks:\n",
    "- an autoencoder on a reconstruction task\n",
    "- a classifier on a classification task\n",
    "\n",
    "In practice, users are often interested in using the embeddings of either. The question, we want to answer now: are the embeddings the same?\n",
    "\n",
    "At this point, we have to honor the fact, that we are dealing with a 10-dim space in either case. Thus, we have to choose a good visualisation method (or any other method to check) how similar, the embeddings actually are.\n",
    "\n",
    "*Exercise 05.2*\n",
    "\n",
    "Perform the study above by fitting a 2-component PCA from `sklearn` on the embedding spaces of the test set! Fix the errors in the visible code snippet first. Then move on to visualize the first 2 components of the PCA.\n",
    "\n",
    "Bonus: If you feel like it, feel free to experiment with other techniques than PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c7ed3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# disable autodiff computations\n",
    "classmodel.eval()\n",
    "autoemodel.eval()\n",
    "\n",
    "alldata_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)\n",
    "alltest_x, alltest_y = next(iter(alldata_loader))\n",
    "\n",
    "allembed_class = ...\n",
    "allembed_autoe = ...\n",
    "\n",
    "assert ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e0d75",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "classmodel.eval()\n",
    "autoemodel.eval()\n",
    "\n",
    "alldata_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)\n",
    "alltest_x, alltest_y = next(iter(alldata_loader))\n",
    "\n",
    "allembed_class = classmodel(alltest_x)\n",
    "allembed_autoe = autoemodel.enc(alltest_x)\n",
    "\n",
    "assert allembed_autoe.shape == allembed_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2043f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_class = pca.fit(allembed_class.detach().numpy()).transform(\n",
    "    allembed_class.detach().numpy()\n",
    ")\n",
    "X_autoe = pca.fit(allembed_autoe.detach().numpy()).transform(\n",
    "    allembed_autoe.detach().numpy()\n",
    ")\n",
    "\n",
    "assert X_class.shape == X_autoe.shape\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "lw = 2\n",
    "\n",
    "ax[0,0].scatter(X_class[..., 0], X_class[..., 1])\n",
    "ax[0,0].set_title(\"PCA of classifier embeddings\")\n",
    "\n",
    "ax[0,1].scatter(X_autoe[..., 0], X_autoe[..., 1])\n",
    "ax[0,1].set_title(\"PCA of autoencoder embeddings\")\n",
    "\n",
    "ax[1,0].scatter(X_class[..., 0], X_class[..., 1], c = alltest_y.detach().numpy())\n",
    "ax[1,0].set_title(\"PCA of classifier embeddings\")\n",
    "\n",
    "ax[1,1].scatter(X_autoe[..., 0], X_autoe[..., 1], c = alltest_y.detach().numpy())\n",
    "ax[1,1].set_title(\"PCA of autoencoder embeddings\")\n",
    "\n",
    "fig.savefig(\"representationlearning-pca-comparison.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e4d64b",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "From the above we learn, that the geometries which each of the two architectures populate in the embedding space tend to be quite different. Hence, the effect of this must be taken into account in practice. Moreover, we also see how clearly different either model differentiates the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
